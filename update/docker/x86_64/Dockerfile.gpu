# syntax=docker/dockerfile:1.7
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

ARG PYTHON_VERSION=3.10
ARG TF_VERSION=2.15.*
ARG ORT_VERSION=1.17.*
ARG DEBIAN_FRONTEND=noninteractive

ENV LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    PYTHONUNBUFFERED=1 \
    TF_CPP_MIN_LOG_LEVEL=1 \
    TF_FORCE_GPU_ALLOW_GROWTH=true \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Paquetes mínimos
RUN apt-get update && apt-get install -y --no-install-recommends \
    python${PYTHON_VERSION} python3-venv python3-pip python3-dev \
    git build-essential ca-certificates curl wget pkg-config \
    libglib2.0-0 libsm6 libxext6 libxrender1 \
 && rm -rf /var/lib/apt/lists/*

# Venv
ENV VENV=/opt/venv
RUN python${PYTHON_VERSION} -m venv ${VENV}
ENV PATH="${VENV}/bin:${PATH}"

# pip moderno
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --upgrade pip setuptools wheel

# Librerías de inferencia (evitamos conda)
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install \
      "tensorflow[and-cuda]==${TF_VERSION}" \
      "onnxruntime-gpu==${ORT_VERSION}" \
      onnx numpy pillow opencv-python-headless \
      pybind11 future cython psutil

# MLPerf LoadGen (Python binding)
WORKDIR /opt/src
RUN git clone --recursive https://github.com/mlcommons/inference.git
WORKDIR /opt/src/inference/loadgen
RUN --mount=type=cache,target=/root/.cache/pip \
    CXXFLAGS="-std=c++14" pip install .

# Workspace por defecto
WORKDIR /workspace

ENTRYPOINT ["/bin/bash"]
